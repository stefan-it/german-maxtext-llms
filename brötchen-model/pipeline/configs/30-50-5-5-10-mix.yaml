tokenizer:
  name: "german-maxtext-slms/broetchen-ablation-1-tokenizer"

datatrove:
  workers: 1
  tasks: 1

datasets:
  finepdfs_english:
    path: "data/eng_Latn/train"
    max_tokens: 20_000_000_000
    output_path: "./30-50-5-5-10-mix"
  finepdfs_german:
    path: "data/deu_Latn/train"
    max_tokens: 100_000_000_000
    output_path: "./30-50-5-5-10-mix"
  fineweb_edu_english:
    path: "sample/10BT"
    max_tokens: 10_000_000_000
    output_path: "./30-50-5-5-10-mix"
  fineweb_english:
    path: "sample/10BT"
    max_tokens: 10_000_000_000
    output_path: "./30-50-5-5-10-mix"
  fineweb2_german:
    path: "data/deu_Latn/train"
    max_tokens: 60_000_000_000
    output_path: "./30-50-5-5-10-mix"
